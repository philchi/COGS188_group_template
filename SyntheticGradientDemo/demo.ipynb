{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module import ModuleWithSyntheticGradient as Syn\n",
    "from module import RegularModule as Reg\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a toy neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = Syn()\n",
    "\n",
    "conv.add_module(name='conv_1', module=nn.Conv2d(3, 32, kernel_size=3, padding=1))\n",
    "conv.add_module(name='relu_1', module=nn.ReLU())\n",
    "conv.add_module(name='maxpooling_1', module=nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "conv.add_module(name='conv_2', module=nn.Conv2d(32, 64, kernel_size=3, padding=1))\n",
    "conv.add_module(name='relu_2', module=nn.ReLU())\n",
    "conv.add_module(name='maxpooling_2', module=nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "conv.add_module(name='conv_3', module=nn.Conv2d(64, 64, kernel_size=3, padding=1))\n",
    "conv.add_module(name='relu_3', module=nn.ReLU())\n",
    "conv.add_module(name='maxpooling_3', module=nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "conv.add_module(name='flatten', module=nn.Flatten())\n",
    "\n",
    "conv.enable_training(1024) # final output will be 64(C) * 4(H) * 4(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = Reg()\n",
    "\n",
    "dense.add_module(name='fc_1', module=nn.Linear(1024, 512))\n",
    "dense.add_module(name='relu_1', module=nn.ReLU())\n",
    "\n",
    "dense.add_module(name='fc_2', module=nn.Linear(512, 10))\n",
    "\n",
    "dense.enable_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "conv.to(device)\n",
    "dense.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1,51):\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "            \n",
    "        conv_output = conv.train_weight(data)\n",
    "        loss = dense.train_weight(conv_output, target)\n",
    "        synthetic_grad_loss = conv.train_synthetic_grad(conv_output.grad)\n",
    "    \n",
    "    # testing\n",
    "    with torch.no_grad():\n",
    "        correct_num = 0\n",
    "        total_num = 0\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            conv_output = conv(data)\n",
    "            mlp_output = dense(conv_output)\n",
    "            result = torch.argmax(mlp_output, dim=-1)\n",
    "            print(result == target)\n",
    "            correct_num += torch.sum(result == target).item()\n",
    "            total_num += result.shape[0]\n",
    "                \n",
    "    print(f'Train Epoch: {epoch}\\tLoss: {loss:.6f}\\tSynthetic Loss: {synthetic_grad_loss:.6f}\\tAccuracy: {correct_num/total_num}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
